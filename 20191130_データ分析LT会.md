# takapyさん

## パイプラインの話/脱Notebook

### コネヒト紹介

- mamari: 3人に1人がママリ使用中

### 3つの制限性を担保する

- 特徴量、パラメタ、CV＋Feature importanceの見える化
  - Jsonに勝手に吐かれるようにする
  - グラフ：標準偏差/平均　⇒　削って良さそうな勘所がつかめる
- 日時Suffixで管理
- PublicスコアをディレクトリのSuffixにつける

------

# nyker_gotoさん (山口貴大さん)

- @atma取締役 京大 最適化数理 SGD

## 初手が爆速になるFW作ってコンペ設計 

- 将棋で言うところの研究で半分くらいが決まる
- vividという名前、pip installできる

### セールスポイント

- Endodong, Single model,
- Optuna ,seed average, stacking/boostingができる

### コンペ課題の設計

- target
  - 候補16種類
- Train/public/privateの切り方
  - 6種類
- 実際に解いた時のスコアの見積もり
  - モデル10種類
- vividで爆速モデリング

### イケてない点

- バグを踏みがち
- 柔軟性に乏しい（APIが隠しすぎるので）
- ドキュメントなし

------

# wakameさん

- 仕事はスマホゲームのQAとAIツールの開発

## LightGBMTunerの話 

- Optunaの新機能に取り込まれたもの

### とは

- Stepwise Tuning
  - パラメタを1個1個Optunaで最適化する感じ
    - それで最適値に行くのかな？
- 調整はコンペでも1－2回にとどめる
  - subsample=0.7で
  - min_child_weightはtrain/valの差が大きいなら増やす
- ハイパラチューニング分からない人向け

### ハイパラチューニング

- feature_fraction
- lambda_l1,l2
- min_child_samples
- 最適化アルゴリズム: TPESampler
- パラメタ探索範囲：経験則で決定しており参考文献なし

### コンペでのベンチマーク

- 過去コンペのテーブルデータを対象
- Private/Publicスコアで比較
- ELO出の結果：Tuneした結果：0.001down、Publicは0.001up(悪い)
- Recruitでも結果：PublicもPrivateも良くなった

### まとめ

- チューニング初心者向け
- ベンチマーク結果を見るとKaggleでも使えそう

------

# shinchiroさん

## Augmentation

- p=0.5: 水平の反転をする確率を表す（1回目の学習、2回目の学習、…）

## 特徴量生成

- 画像では意識しない；NNにそのまま突っ込むので

## モデル

- Unet
- FPN
- Endoderで畳みこんだものをDecoderで復元する
  - Encoder: Mask-RCNNを利用

### 分からなかったこと

- BCE + Dice Lossの足し合わせの意味
- Layerの設計方法
- 複数枚GPUの活用法

------

# Sponser talk: 日経BP 谷井さん@医療メディア編成部

## 日経メディカル

- 意志薬剤師の1/2人が登録している
- データ処理基盤Atlas
  - SQLでデータ分析
- 企業間を超えて分析できる市場
  - 各社が持っているデータを共有して分析できる

## メンバー募集中

- PdMとDSが二人三脚で検証と企画を行うのが当然（シリコンバレーに倣う）
- @aki_honmono

------

# fam_taroさん

## 実践PyTorch Lightning

- waseda修士 NLP
- LPIXEL 画像処理をしている

### とは

- PyTorch前提
- オレオレTrainerクラスはメンテ大変

### Start

- Lightning moduleの作成
- Trainer作成：multi-GPUオプションなど
  - 購買累積の部分
- trainer.fitで実行するだけ

### 注意点

- Stableなバージョンでない、後方互換性はない
- MultiGPUかつMixedPresicionTrainingの洗濯しがDDPのみ
- コード量が減るわけではない

### 感想と結論

- 発展途上だけど期待大
- Ignite、Lightningなど似たようなものが並んでいる
- Single-GPUなら使う分には問題なさそう

### QA

- 1GPUよりはバッチサイズ増やせるので安定しやすいのでMulti-GPUならDDPがおすすめ
  - ただしギリギリの調整の場合に限る
  - デメリットとしてバリデーションの部分では分割せずにトータル計算なので時間がかかる

------

# 紺さん

## NSSOL Yu Ohoriさん

- 半教師ありの研究、異常検知の研究、DataOpsの開発

## AutoML

- 欠損値補完、外れ値除去、特徴抽出、Aug, モデル選択、ハイパラ探索などをやってくれる
- 今年はAutoMLコンペが豊作

## AutoMLコンペの特徴

- データセット複数(最終評価はガチ未知の評価)
- 匿名加工
- 計算資源や時間成約がある
- 精度だけじゃなく時間も評価される

## AutoWSL (弱教師あり学習AutoMLコンペ)

- 5つの表形式データセット
- 成約：4CPU、数十分程度
- AUROC
- 半教師あり、ノイジーラベルデータ

### 解法

- Feature Engineering ->数値型のClip, timeを捨てるなど簡単なもの
  - SSL classifier
    - ラベル付きデータで学習->ラベルなしデータで予測->革新度の高いデータをラベル付きデータに追加
      - 誤るラベルが出る可能性があるのでNoisyClassifierにあとは任せる
  - PU Classifier
  - NoisyClassifier
    - BoostingはNoisy labelに敏感なので探索空間にRFを追加
    - Noisy labelを多く含む場合AUROCが不正確->SCE（対称クロスエントロピー）の利用を検討
- OptGBM＝OptunaとLightGBMをリリースしている

### 最後に

- NeurIPSでAutoSpeechの話を発表
- 1位の回答は半教師ありにしていない、生霊と不例しか使っていないらしい。また、Noisy ClassifierでLogistic Regressionでクリーニングする

------

# mhiro2さん

## 分析用オンプレマシン構築

- MLOps Engineer 

### モチベ

- GPUカーネル制限

### 意義

- 無くても勝てるが、ハードルは高い
- 参加できるコンペの幅を広げられる
- 試行回数が増やせる
- クラウドは高くつきやすい

### CPU

- コア数、スレッド数、が最重要
- クロック周波数
- Pythonはマルチプロセス並列化になる->メモリ積んでおく必要あり

### GPU

- 2080 Tiをとりあえず買う
- メーカーが違っても中身が同じなので好み次第
- 外排気or内排気
- どれを買うか
  - Turing世代：RTX20XX, RTX
- Titan RTX
- RTX 2080
- 温度に気を付ける
- 環境構築
  - Nvidia-docker
- 複数GPUで気を付けること
- クラスタ構成は構築ハードル高い

------

# kaerururuさん

- AIベンチャーでNLP関連の検証、プロダクト化

## Discussion text data 

### 利用データ

- Meta Kaggle
- Discussion関連はforum*.csv

### EDA

- HTMLタグや特殊文字削除

### BERT

- Acc50%くらいしか行かなかった；単語の持っている意味はあまりない（BERTの分散表現ではだめそう）

------

# hakubishinさん

- 推薦チーム＠Wantedly社

## Target Encodingがなぜ有効か

- Label Encodingよりも効く理由

### Target Encodingとは

- カテゴリ変数を各水準における目的変数の期待値で置換する

### なぜか

- モデルを単純化させる効果を持つ
- 損失関数がMSEの場合、葉jの残差平均
- 葉における最適Weightの場所の当てはまりの良さで切っていく
- Target Encodingがシンプルなモデルで当てはまりがよくなる
- 木構造をシンプルにするので、残差の大きさが近い水準同士をより近い位置に配置している
- 水準数が多ければ多いほど実感しやすい、Lossを効率的に減少できる

### 深いとダメなのか？

- 数値特徴量のInterationと同じで、明示的にモデルに渡したほうがいい

### QA

- 1000,10000だとLabelでやる価値無しと思う、100くらいならとりあえず入れてみる（効かなそうなら抜く）
